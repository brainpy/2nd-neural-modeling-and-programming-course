{"cells":[{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"55655974444244BD90F799E8C21725E9","notebookId":"64ebf74cf2211668f8332551","trusted":true},"source":"# -*- coding: utf-8 -*-\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport brainpy as bp\nimport brainpy.math as bm\n","outputs":[],"execution_count":1},{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"933BA876020C4582819822B8DDA08B86","runtime":{"status":"default","execution_status":null},"notebookId":"64ebf74cf2211668f8332551"},"source":"# **The Cortical Network Model for Decision-Making**  \n\nThe network is composed of N neurons, with NE pyramidal cells (80%) and NI interneurons (20%) (Braitenberg and Schütz 1991).  \nSimulations reported in here were done with NE = 1600, NI = 400.  \nEach stimulus activates a distinct and small subpopulation of fNE excitatory cells (f = 0.15).  \n\n**Neurons**  \n\nBoth pyramidal cells and interneurons are described by leaky integrate-and-fire neurons (see for example Tuckwell 1988) and are characterized by a resting potential VL = −70 mV, a firing threshold Vth = −50 mV, a reset potential Vreset = −55 mV, a membrane capacitance Cm = 0.5 nF for pyramidal cells and 0.2 nF for interneurons, a membrane leak conductance gL = 25 nS for pyramidal cells and 20 nS for interneurons, and a refractory period τref = 2 ms for pyramidal cells and 1 ms for interneurons. The corresponding membrane time constants are τm = Cm/gL = 20 ms for excitatory cells and 10 ms for interneurons (McCormick et al. 1985). Below threshold, the membrane potential V(t) of a cell  \n\n$$  \nC_m \\frac{d V(t)}{d t}=-g_L\\left(V(t)-V_L\\right)-I_{s y n}(t)  \n$$  \n\nwhere Isyn(t) represents the total synaptic current flowing into the cell.  \n\n\n**Synapses**  \n\nThe total synaptic currents are given by:  \n\n$$  \nI_{s y n}(t)=I_{\\text {ext,AMPA }}(t)+I_{\\text {rec }, A M P A}(t)+I_{\\text {rec }, N M D A}(t)+I_{\\text {rec }, \\mathrm{GABA}}(t)  \n$$  \n\nin which  \n\n$$  \n\\begin{gathered}  \nI_{\\text {ext,AMPA }}(t)=g_{\\text {ext,AMPA }}\\left(V(t)-V_E\\right) s^{\\text {ext,AMPA }}(t) \\\\  \nI_{\\text {rec,AMPA }}(t)=g_{\\text {rec,AMPA }}\\left(V(t)-V_E\\right) \\sum_{j=1}^{C_E} w_j s_j^{A M P A}(t) \\\\  \nI_{\\text {rec,NMDA }}(t)=\\frac{g_{\\mathrm{NMDA}}\\left(V(t)-V_E\\right)}{\\left(1+\\left[\\mathrm{Mg}^{2+}\\right] \\exp (-0.062 V(t)) / 3.57\\right)} \\sum_{j=1}^{\\mathrm{C}_E} w_j s_j^{\\mathrm{NMDA}}(t) \\\\  \nI_{\\mathrm{rec}, \\mathrm{GABA}}(t)=g_{\\mathrm{GABA}}\\left(V(t)-V_l\\right) \\sum_{j=1}^{C_1} s_j^{\\mathrm{GABA}}(t)  \n\\end{gathered}  \n$$  \n\nwhere VE = 0 mV, VI = −70 mV.  \n\n**Synaptic Weights**  \n\nHence, inside a selective population, $w_j$ = w+, where w+ > 1 is a dimensionless parameter that is equal to the relative strength of “potentiated” synapses with respect to the baseline. Unless specified otherwise, I used w+ = 1.7.  \n\nBetween two different selective populations, and from the nonselective population to selective ones, $w_j$ = w−, where w− < 1 measures the strength of synaptic “depression.” $w− = 1 − f(w_+ − 1)/(1 − f)$.  \n\nOther connections have $w_j$ = 1.  \n\n\n**References:**  \n\n-Wang XJ. Probabilistic Decision Making by Slow Reverberation in Cortical Circuits. Neuron. 2002;36(5):955-968. doi:10.1016/S0896-6273(02)01092-9  \n"},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"5F589FD4B4A04D158A62EB5433E2A055","notebookId":"64ebf74cf2211668f8332551","trusted":true},"source":"class AMPA(bp.Projection):\n  def __init__(self, pre, post, conn, delay, g_max, tau, E):\n    super().__init__()\n    if conn == 'all2all':\n      comm = bp.dnn.AllToAll(pre.num, post.num, g_max)\n    elif conn == 'one2one':\n      comm = bp.dnn.OneToOne(pre.num, g_max)\n    else:\n      raise ValueError\n    syn = bp.dyn.Expon.desc(post.num, tau=tau)\n    out = bp.dyn.COBA.desc(E=E)\n    self.proj = bp.dyn.ProjAlignPostMg2(\n      pre=pre, delay=delay, comm=comm,\n      syn=syn, out=out, post=post\n    )\n\n\nclass NMDA(bp.Projection):\n  def __init__(self, pre, post, conn, delay, g_max):\n    super().__init__()\n    if conn == 'all2all':\n      comm = bp.dnn.AllToAll(pre.num, post.num, g_max)\n    elif conn == 'one2one':\n      comm = bp.dnn.OneToOne(pre.num, g_max)\n    else:\n      raise ValueError\n    syn = bp.dyn.NMDA.desc(pre.num, a=0.5, tau_decay=100., tau_rise=2.)\n    out = bp.dyn.MgBlock(E=0., cc_Mg=1.0)\n    self.proj = bp.dyn.ProjAlignPreMg2(\n      pre=pre, delay=delay, syn=syn,\n      comm=comm, out=out, post=post\n    )\n","outputs":[],"execution_count":2},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"77186C726A0240598EAA5BFC00746A58","notebookId":"64ebf74cf2211668f8332551","trusted":true},"source":"class DecisionMakingNet(bp.DynSysGroup):\n  def __init__(self, scale=1., f=0.15):\n    super().__init__()\n    # 网络中各组神经元的数目\n    num_exc = int(1600 * scale)\n    num_I, num_A, num_B = int(400 * scale), int(f * num_exc), int(f * num_exc)\n    num_N = num_exc - num_A - num_B\n    self.num_A, self.num_B, self.num_N, self.num_I = num_A, num_B, num_N, num_I\n\n    poisson_freq = 2400.  # Hz\n    w_pos = 1.7\n    w_neg = 1. - f * (w_pos - 1.) / (1. - f)\n    g_ext2E_AMPA = 2.1  # nS\n    g_ext2I_AMPA = 1.62  # nS\n    g_E2E_AMPA = 0.05 / scale  # nS\n    g_E2I_AMPA = 0.04 / scale  # nS\n    g_E2E_NMDA = 0.165 / scale  # nS\n    g_E2I_NMDA = 0.13 / scale  # nS\n    g_I2E_GABAa = 1.3 / scale  # nS\n    g_I2I_GABAa = 1.0 / scale  # nS\n\n    neu_par = dict(V_rest=-70., V_reset=-55., V_th=-50., V_initializer=bp.init.OneInit(-70.))\n\n    # E neurons/pyramid neurons\n    self.A = bp.dyn.LifRef(num_A, tau=20., R=0.04, tau_ref=2., **neu_par)\n    self.B = bp.dyn.LifRef(num_B, tau=20., R=0.04, tau_ref=2., **neu_par)\n    self.N = bp.dyn.LifRef(num_N, tau=20., R=0.04, tau_ref=2., **neu_par)\n\n    # I neurons/interneurons\n    self.I = bp.dyn.LifRef(num_I, tau=10., R=0.05, tau_ref=1., **neu_par)\n\n    # poisson stimulus  # 'freqs' as bm.Variable\n    self.IA = bp.dyn.PoissonGroup(num_A, freqs=bm.Variable(bm.zeros(1)))\n    self.IB = bp.dyn.PoissonGroup(num_B, freqs=bm.Variable(bm.zeros(1)))\n\n    # noise neurons\n    self.noise_B = bp.dyn.PoissonGroup(num_B, freqs=poisson_freq)\n    self.noise_A = bp.dyn.PoissonGroup(num_A, freqs=poisson_freq)\n    self.noise_N = bp.dyn.PoissonGroup(num_N, freqs=poisson_freq)\n    self.noise_I = bp.dyn.PoissonGroup(num_I, freqs=poisson_freq)\n\n    # define external inputs\n    #### TO DO!!!!\n    self.IA2A = AMPA(self.IA, self.A, 'one2one', None, g_ext2E_AMPA, tau=2., E=0.)\n    self.IB2B = AMPA(self.IB, self.B, 'one2one', None, g_ext2E_AMPA, tau=2., E=0.)\n\n    # define AMPA projections from N\n    #### TO DO!!!!\n    self.N2B_AMPA = AMPA(self.N, self.B, 'all2all', 0.5, g_E2E_AMPA * w_neg, tau=2., E=0.)\n    self.N2A_AMPA = AMPA(self.N, self.A, 'all2all', 0.5, g_E2E_AMPA * w_neg, tau=2., E=0.)\n    self.N2N_AMPA = AMPA(self.N, self.N, 'all2all', 0.5, g_E2E_AMPA, tau=2., E=0.)\n    self.N2I_AMPA = AMPA(self.N, self.I, 'all2all', 0.5, g_E2I_AMPA, tau=2., E=0.)\n\n    # define NMDA projections from N\n    #### TO DO!!!!\n    self.N2B_NMDA = NMDA(self.N, self.B, 'all2all', 0.5, g_E2E_NMDA * w_neg)\n    self.N2A_NMDA = NMDA(self.N, self.A, 'all2all', 0.5, g_E2E_NMDA * w_neg)\n    self.N2N_NMDA = NMDA(self.N, self.N, 'all2all', 0.5, g_E2E_NMDA)\n    self.N2I_NMDA = NMDA(self.N, self.I, 'all2all', 0.5, g_E2I_NMDA)\n\n    # define AMPA projections from B\n    #### TO DO!!!!\n    self.B2B_AMPA = AMPA(self.B, self.B, 'all2all', 0.5, g_E2E_AMPA * w_pos, tau=2., E=0.)\n    self.B2A_AMPA = AMPA(self.B, self.A, 'all2all', 0.5, g_E2E_AMPA * w_neg, tau=2., E=0.)\n    self.B2N_AMPA = AMPA(self.B, self.N, 'all2all', 0.5, g_E2E_AMPA, tau=2., E=0.)\n    self.B2I_AMPA = AMPA(self.B, self.I, 'all2all', 0.5, g_E2I_AMPA, tau=2., E=0.)\n\n    # define NMDA projections from B\n    #### TO DO!!!!\n    self.B2B_NMDA = NMDA(self.B, self.B, 'all2all', 0.5, g_E2E_NMDA * w_pos)\n    self.B2A_NMDA = NMDA(self.B, self.A, 'all2all', 0.5, g_E2E_NMDA * w_neg)\n    self.B2N_NMDA = NMDA(self.B, self.N, 'all2all', 0.5, g_E2E_NMDA)\n    self.B2I_NMDA = NMDA(self.B, self.I, 'all2all', 0.5, g_E2I_NMDA)\n\n    # define AMPA projections from A\n    #### TO DO!!!!\n    self.A2B_AMPA = AMPA(self.A, self.B, 'all2all', 0.5, g_E2E_AMPA * w_neg, tau=2., E=0.)\n    self.A2A_AMPA = AMPA(self.A, self.A, 'all2all', 0.5, g_E2E_AMPA * w_pos, tau=2., E=0.)\n    self.A2N_AMPA = AMPA(self.A, self.N, 'all2all', 0.5, g_E2E_AMPA, tau=2., E=0.)\n    self.A2I_AMPA = AMPA(self.A, self.I, 'all2all', 0.5, g_E2I_AMPA, tau=2., E=0.)\n\n    # define NMDA projections from A\n    #### TO DO!!!!\n    self.A2B_NMDA = NMDA(self.A, self.B, 'all2all', 0.5, g_E2E_NMDA * w_neg)\n    self.A2A_NMDA = NMDA(self.A, self.A, 'all2all', 0.5, g_E2E_NMDA * w_pos)\n    self.A2N_NMDA = NMDA(self.A, self.N, 'all2all', 0.5, g_E2E_NMDA)\n    self.A2I_NMDA = NMDA(self.A, self.I, 'all2all', 0.5, g_E2I_NMDA)\n\n    # define I->E/I conn\n    #### TO DO!!!! 用AMPA()\n    self.I2B = AMPA(self.I, self.B, 'all2all', 0.5, g_I2E_GABAa, tau=5., E=-70.)\n    self.I2A = AMPA(self.I, self.A, 'all2all', 0.5, g_I2E_GABAa, tau=5., E=-70.)\n    self.I2N = AMPA(self.I, self.N, 'all2all', 0.5, g_I2E_GABAa, tau=5., E=-70.)\n    self.I2I = AMPA(self.I, self.I, 'all2all', 0.5, g_I2I_GABAa, tau=5., E=-70.)\n\n    # define external projections\n    #### TO DO!!!!\n    self.noise2B = AMPA(self.noise_B, self.B, 'one2one', None, g_ext2E_AMPA, tau=2., E=0.)\n    self.noise2A = AMPA(self.noise_A, self.A, 'one2one', None, g_ext2E_AMPA, tau=2., E=0.)\n    self.noise2N = AMPA(self.noise_N, self.N, 'one2one', None, g_ext2E_AMPA, tau=2., E=0.)\n    self.noise2I = AMPA(self.noise_I, self.I, 'one2one', None, g_ext2I_AMPA, tau=2., E=0.)\n","outputs":[],"execution_count":3},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"51CCE07DFE64409DAD088F401C0C0015","notebookId":"64ebf74cf2211668f8332551","trusted":true},"source":"class Tool:\n  def __init__(self, pre_stimulus_period=100., stimulus_period=1000., delay_period=500.):\n    self.pre_stimulus_period = pre_stimulus_period\n    self.stimulus_period = stimulus_period\n    self.delay_period = delay_period\n    self.freq_variance = 10.\n    self.freq_interval = 50.\n    self.total_period = pre_stimulus_period + stimulus_period + delay_period\n\n  def generate_freqs(self, mean):\n    # stimulus period\n    n_stim = int(self.stimulus_period / self.freq_interval)\n    n_interval = int(self.freq_interval / bm.get_dt())\n    freqs_stim = np.random.normal(mean, self.freq_variance, (n_stim, 1))\n    freqs_stim = np.tile(freqs_stim, (1, n_interval)).flatten()\n    # pre stimulus period\n    freqs_pre = np.zeros(int(self.pre_stimulus_period / bm.get_dt()))\n    # post stimulus period\n    freqs_delay = np.zeros(int(self.delay_period / bm.get_dt()))\n    all_freqs = np.concatenate([freqs_pre, freqs_stim, freqs_delay], axis=0)\n    return bm.asarray(all_freqs)\n\n  def visualize_results(self, mon, IA_freqs, IB_freqs, t_start=0., title=None):\n    fig, gs = bp.visualize.get_figure(4, 1, 3, 10)\n    axes = [fig.add_subplot(gs[i, 0]) for i in range(4)]\n\n    ax = axes[0]\n    bp.visualize.raster_plot(mon['ts'], mon['A.spike'], markersize=1, ax=ax)\n    if title: ax.set_title(title)\n    ax.set_ylabel(\"Group A\")\n    ax.set_xlim(t_start, self.total_period + 1)\n    ax.axvline(self.pre_stimulus_period, linestyle='dashed')\n    ax.axvline(self.pre_stimulus_period + self.stimulus_period, linestyle='dashed')\n    ax.axvline(self.pre_stimulus_period + self.stimulus_period + self.delay_period, linestyle='dashed')\n\n    ax = axes[1]\n    bp.visualize.raster_plot(mon['ts'], mon['B.spike'], markersize=1, ax=ax)\n    ax.set_ylabel(\"Group B\")\n    ax.set_xlim(t_start, self.total_period + 1)\n    ax.axvline(self.pre_stimulus_period, linestyle='dashed')\n    ax.axvline(self.pre_stimulus_period + self.stimulus_period, linestyle='dashed')\n    ax.axvline(self.pre_stimulus_period + self.stimulus_period + self.delay_period, linestyle='dashed')\n\n    ax = axes[2]\n    rateA = bp.measure.firing_rate(mon['A.spike'], width=10.)\n    rateB = bp.measure.firing_rate(mon['B.spike'], width=10.)\n    ax.plot(mon['ts'], rateA, label=\"Group A\")\n    ax.plot(mon['ts'], rateB, label=\"Group B\")\n    ax.set_ylabel('Population activity [Hz]')\n    ax.set_xlim(t_start, self.total_period + 1)\n    ax.axvline(self.pre_stimulus_period, linestyle='dashed')\n    ax.axvline(self.pre_stimulus_period + self.stimulus_period, linestyle='dashed')\n    ax.axvline(self.pre_stimulus_period + self.stimulus_period + self.delay_period, linestyle='dashed')\n    ax.legend()\n\n    ax = axes[3]\n    ax.plot(mon['ts'], IA_freqs, label=\"group A\")\n    ax.plot(mon['ts'], IB_freqs, label=\"group B\")\n    ax.set_ylabel(\"Input activity [Hz]\")\n    ax.set_xlim(t_start, self.total_period + 1)\n    ax.axvline(self.pre_stimulus_period, linestyle='dashed')\n    ax.axvline(self.pre_stimulus_period + self.stimulus_period, linestyle='dashed')\n    ax.axvline(self.pre_stimulus_period + self.stimulus_period + self.delay_period, linestyle='dashed')\n    ax.legend()\n    ax.set_xlabel(\"Time [ms]\")\n\n    plt.show()","outputs":[],"execution_count":4},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"E92921C7A8C248E681B6ED74A6AFBC5E","notebookId":"64ebf74cf2211668f8332551","trusted":true},"source":"tool = Tool()\nnet = DecisionMakingNet()\n\nmu0 = 40.\ncoherence = 25.6\nIA_freqs = tool.generate_freqs(mu0 + mu0 / 100. * coherence)\nIB_freqs = tool.generate_freqs(mu0 - mu0 / 100. * coherence)\n\ndef give_input():\n    i = bp.share['i']\n    net.IA.freqs[0] = IA_freqs[i]\n    net.IB.freqs[0] = IB_freqs[i]\n\nrunner = bp.DSRunner(net, inputs=give_input, monitors=['A.spike', 'B.spike'])\nrunner.run(tool.total_period)\ntool.visualize_results(runner.mon, IA_freqs, IB_freqs)\n","outputs":[{"output_type":"stream","name":"stderr","text":"No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14b0df0b0364d2490e964fc718016dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x864 with 4 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/E92921C7A8C248E681B6ED74A6AFBC5E/s02um21gbl.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":5},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"5CB5DC6F8EB6467880A38F971766FD9E","notebookId":"64ebf74cf2211668f8332551","trusted":true},"source":"#测试多次随机猜测时候决策网路的表现\ntool = Tool()\nnet = DecisionMakingNet()\n\nmu0 = 40.\ncoherence = 0.\nIA_freqs = tool.generate_freqs(mu0 + mu0 / 100. * coherence)\nIB_freqs = tool.generate_freqs(mu0 - mu0 / 100. * coherence)\n\ndef give_input():\n    i = bp.share['i']\n    net.IA.freqs[0] = IA_freqs[i]\n    net.IB.freqs[0] = IB_freqs[i]\n\nrunner = bp.DSRunner(net, inputs=give_input, monitors=['A.spike', 'B.spike'])\nrunner.run(tool.total_period)\ntool.visualize_results(runner.mon, IA_freqs, IB_freqs)\n\ntool = Tool()\nnet = DecisionMakingNet()\n\nmu0 = 40.\ncoherence = 0.\nIA_freqs = tool.generate_freqs(mu0 + mu0 / 100. * coherence)\nIB_freqs = tool.generate_freqs(mu0 - mu0 / 100. * coherence)\n\ndef give_input():\n    i = bp.share['i']\n    net.IA.freqs[0] = IA_freqs[i]\n    net.IB.freqs[0] = IB_freqs[i]\n\nrunner = bp.DSRunner(net, inputs=give_input, monitors=['A.spike', 'B.spike'])\nrunner.run(tool.total_period)\ntool.visualize_results(runner.mon, IA_freqs, IB_freqs)","outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"665f6c910ead459aad65b1266344cb34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x864 with 4 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/5CB5DC6F8EB6467880A38F971766FD9E/s02um76cff.png\">"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3876700b0d1f46b68135962fc9759ecb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x864 with 4 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/5CB5DC6F8EB6467880A38F971766FD9E/s02umciz2n.png\">"},"metadata":{"needs_background":"light"}}],"execution_count":6},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"4A25DC557C8740BA83C9673A76488560","notebookId":"64ebf74cf2211668f8332551","trusted":true},"source":"","outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}